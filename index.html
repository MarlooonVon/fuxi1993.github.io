<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />








  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>



  
    <link href='//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  


<link rel="stylesheet" type="text/css" href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" />

<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.2"/>




  <meta name="keywords" content="Hexo,next" />





  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.2" />


<meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="My Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="My Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="My Blog">
<meta name="twitter:description">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    sidebar: 'post'
  };
</script>



  <title> My Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  






  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">My Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-/"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-/categories"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-/about"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-/archives"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-/tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 
  <section id="posts" class="posts-expand">
    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2016/03/24/Design-Pattern-1-Factory-Method/" itemprop="url">
                  Design Pattern (1): Factory Method
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2016-03-24T19:54:08+08:00" content="2016-03-24">
              2016-03-24
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h2 id="1-_写在前面">1. 写在前面</h2><p>记得15年5月自己仔细看了《Head First设计模式》，顿时觉得自己对面向对象的设计理念的理解还有很多缺陷，正好这个学期的高级软件工程课程主要讲的就是面向模式的软件体系架构，自己也准备将Java作为自己的第一编译运行语言，所以决心结合设计模式理念和Java语言实例，深入学习一下设计模式理念。</p>
<h2 id="2-_动机">2. 动机</h2><p>考虑这样一个应用框架，它可以向用户显示多个文档。在这个框架中，两个主要的抽象是类Application和Document。这两个类都是抽象的，客户必须通过它们的子类来做与具体应用相关的实现。例如，为创建一个绘图应用，我们定义类 DrawingApplication和DrawDocument。Application类负责管理Document并根据需要创建它们—例如，当用户从菜单中选择Open或New的时候。<br><em>出现的问题</em>：Application类仅知道一个新的文档何时应被创建，而不知道哪一种Document将被创建。这就产生了一个尴尬的局面：框架必须实例化类，但是它只知道不能被实例化的抽象类。<br><em>解决方案</em>：Factory Method模式提供了一个解决办案。它封装了哪一个Document子类将被创建的信息并将这些信息从该框架中分离出来。<br>Application的子类重定义 Application的抽象操作 CreatDocument以返回适当的 Document子类对象。一旦一个 Application子类实例化以后，它就可以实例化与应用相关的文档，而无需知道这些文档的类(非抽象类)。我们称CreateDocument是一个<em>工厂方法（factory method）</em>，因为它负责“生产”一个对象。<br><img src="/images/DP/FM/1.PNG" alt="picture"></p>
<h2 id="3-_意图">3. 意图</h2><p>定义一个用于创建对象的<em>接口</em>，让子类决定实例化哪一个类。Factory Method使一个类的实例化延迟到其子类。</p>
<h2 id="4-_适用性">4. 适用性</h2><p>在下列情况下可以使用 Factory Method模式：<br>• 当一个类(Creator)不知道它所必须创建的对象的类的时候。<br>• 当一个类(Creator)希望由它的子类来指定它所创建的对象的时候。<br>• 当类将创建对象的职责委托给多个帮助子类中的某一个，并且你希望将哪一个帮助子类<br>是代理者这一信息局部化的时候。</p>
<h2 id="5-_结构">5. 结构</h2><p><img src="/images/DP/FM/2.PNG" alt="picture"></p>
<h2 id="6-_参与者">6. 参与者</h2><p>• Product(Document)<br>— 定义工厂方法所创建的对象的接口。<br>• ConcreteProduct(MyDocument)<br>— 实现Product接口。<br>• Creator(Application)<br>— 声明工厂方法，该方法返回一个Product类型的对象。 Creator也可以定义一个工厂方<br>法的缺省实现，它返回一个缺省的ConcreteProduct对象。<br>— 可以调用工厂方法以创建一个Product对象。<br>• ConcreteCreator（MyApplication）<br>— 重定义工厂方法以返回一个ConcreteProduct实例。</p>
<h2 id="7-_协作">7. 协作</h2><p>• Creator依赖于它的子类来定义工厂方法，所以它返回一个适当的ConcreteProduct实例。</p>
<h2 id="8-_实例：Factory_design_pattern_used_in_Java_Library">8. 实例：Factory design pattern used in Java Library</h2><p>根据不同的参数，getInstance()返回一个Canlander不同的实例<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">java.util.Calendar - getInstance()</span><br><span class="line">java.util.Calendar - getInstance(TimeZone zone)</span><br><span class="line">java.util.Calendar - getInstance(Locale aLocale)</span><br><span class="line">java.util.Calendar - getInstance(TimeZone zone, Locale aLocale)</span><br><span class="line">java.text.NumberFormat - getInstance()</span><br><span class="line">java.text.NumberFormat - getInstance(Locale inLocale)</span><br></pre></td></tr></table></figure></p>
<p>可在<a href="http://www.javased.com/?action=source-search" target="_blank" rel="external">javased.com</a>找到Calendar和NumberFormat的源代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line"> * Gets a calendar using the default time zone and locale. The </span><br><span class="line"> * &lt;code&gt;Calendar&lt;/code&gt; returned is based on the current time </span><br><span class="line"> * in the default time zone with the default locale. </span><br><span class="line"> * </span><br><span class="line"> * <span class="doctag">@return</span> a Calendar. </span><br><span class="line"> */</span> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Calendar <span class="title">getInstance</span><span class="params">()</span> </span><br><span class="line"></span>&#123; </span><br><span class="line">    Calendar cal = createCalendar(TimeZone.getDefaultRef(), Locale.getDefault(Locale.Category.FORMAT)); </span><br><span class="line">    cal.sharedZone = <span class="keyword">true</span>; </span><br><span class="line">    <span class="keyword">return</span> cal; </span><br><span class="line">&#125; </span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Gets a calendar using the specified time zone and default locale. </span><br><span class="line"> * The &lt;code&gt;Calendar&lt;/code&gt; returned is based on the current time </span><br><span class="line"> * in the given time zone with the default locale. </span><br><span class="line"> * </span><br><span class="line"> * <span class="doctag">@param</span> zone the time zone to use </span><br><span class="line"> * <span class="doctag">@return</span> a Calendar. </span><br><span class="line"> */</span> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Calendar <span class="title">getInstance</span><span class="params">(TimeZone zone)</span> </span><br><span class="line"></span>&#123; </span><br><span class="line">    <span class="keyword">return</span> createCalendar(zone, Locale.getDefault(Locale.Category.FORMAT)); </span><br><span class="line">&#125; </span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Gets a calendar using the default time zone and specified locale. </span><br><span class="line"> * The &lt;code&gt;Calendar&lt;/code&gt; returned is based on the current time </span><br><span class="line"> * in the default time zone with the given locale. </span><br><span class="line"> * </span><br><span class="line"> * <span class="doctag">@param</span> aLocale the locale for the week data </span><br><span class="line"> * <span class="doctag">@return</span> a Calendar. </span><br><span class="line"> */</span> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Calendar <span class="title">getInstance</span><span class="params">(Locale aLocale)</span> </span><br><span class="line"></span>&#123; </span><br><span class="line">    Calendar cal = createCalendar(TimeZone.getDefaultRef(), aLocale); </span><br><span class="line">    cal.sharedZone = <span class="keyword">true</span>; </span><br><span class="line">    <span class="keyword">return</span> cal; </span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Gets a calendar with the specified time zone and locale. </span><br><span class="line"> * The &lt;code&gt;Calendar&lt;/code&gt; returned is based on the current time </span><br><span class="line"> * in the given time zone with the given locale. </span><br><span class="line"> * </span><br><span class="line"> * <span class="doctag">@param</span> zone the time zone to use </span><br><span class="line"> * <span class="doctag">@param</span> aLocale the locale for the week data </span><br><span class="line"> * <span class="doctag">@return</span> a Calendar. </span><br><span class="line"> */</span> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Calendar <span class="title">getInstance</span><span class="params">(TimeZone zone, </span><br><span class="line">                                   Locale aLocale)</span> </span><br><span class="line"></span>&#123; </span><br><span class="line">    <span class="keyword">return</span> createCalendar(zone, aLocale); </span><br><span class="line">&#125; </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Calendar <span class="title">createCalendar</span><span class="params">(TimeZone zone, </span><br><span class="line">                                       Locale aLocale)</span> </span><br><span class="line"></span>&#123; </span><br><span class="line">    Calendar cal = <span class="keyword">null</span>; </span><br><span class="line"> </span><br><span class="line">    String caltype = aLocale.getUnicodeLocaleType(<span class="string">"ca"</span>); </span><br><span class="line">    <span class="keyword">if</span> (caltype == <span class="keyword">null</span>) &#123; </span><br><span class="line">        <span class="comment">// Calendar type is not specified. </span></span><br><span class="line">        <span class="comment">// If the specified locale is a Thai locale, </span></span><br><span class="line">        <span class="comment">// returns a BuddhistCalendar instance. </span></span><br><span class="line">        <span class="keyword">if</span> (<span class="string">"th"</span>.equals(aLocale.getLanguage()) </span><br><span class="line">                &amp;&amp; (<span class="string">"TH"</span>.equals(aLocale.getCountry()))) &#123; </span><br><span class="line">            cal = <span class="keyword">new</span> BuddhistCalendar(zone, aLocale); </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">            cal = <span class="keyword">new</span> GregorianCalendar(zone, aLocale); </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (caltype.equals(<span class="string">"japanese"</span>)) &#123; </span><br><span class="line">        cal = <span class="keyword">new</span> JapaneseImperialCalendar(zone, aLocale); </span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (caltype.equals(<span class="string">"buddhist"</span>)) &#123; </span><br><span class="line">        cal = <span class="keyword">new</span> BuddhistCalendar(zone, aLocale); </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        <span class="comment">// Unsupported calendar type. </span></span><br><span class="line">        <span class="comment">// Use Gregorian calendar as a fallback. </span></span><br><span class="line">        cal = <span class="keyword">new</span> GregorianCalendar(zone, aLocale); </span><br><span class="line">    &#125; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> cal; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="参考资料">参考资料</h2><ol>
<li><a href="https://book.douban.com/subject/1052241/" target="_blank" rel="external">设计模式-可复用面向对象软件的基础</a></li>
<li><a href="https://book.douban.com/subject/2243615/" target="_blank" rel="external">Head First设计模式</a></li>
<li><a href="http://www.programcreek.com/" target="_blank" rel="external">Programcreek</a></li>
<li><a href="http://blog.csdn.net/sfdev/article/details/3906243" target="_blank" rel="external">UML中几种类间关系：继承、实现、依赖、关联、聚合、组合的联系与区别</a></li>
</ol>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2016/03/16/Datacenter-Network-Simulation-using-Mininet/" itemprop="url">
                  Datacenter Network Simulation using Mininet
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2016-03-16T22:10:35+08:00" content="2016-03-16">
              2016-03-16
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h2 id="一-_实验环境">一. 实验环境</h2><p>Ubuntu 14.04 LTS (GNU/Linux 3.13.0-24-generic i686), mininet 2.2.1, puTTY, Xming等</p>
<h2 id="二-_实验步骤">二. 实验步骤</h2><ol>
<li>安装ubuntu14.04：将实验用的Ubuntu虚拟机磁盘镜像导入到VMware workstation中启动，为虚拟机的网卡分配ip地址；</li>
<li>在宿主机上通过putty登录上已经启动的虚拟机：<br><img src="/images/SDN/1.png" alt="picture"></li>
<li>下载，安装，配置Xming，完成后重启Xming；</li>
<li>在虚拟机上键入“xterm”，出现如下：<br><img src="/images/SDN/2.png" alt="picture"><br>说明能正常启动xterm；</li>
<li>分别针对两个实验要求，设计，完成相关的实验；</li>
</ol>
<h2 id="三-_网络拓扑">三. 网络拓扑</h2><p><img src="/images/SDN/3.png" alt="picture"></p>
<h2 id="四-_实验一：With_Controller:_spanning_tree,_like_failures">四. 实验一：With Controller: spanning tree, like failures</h2><h3 id="1_利用miniedit完成上述网络拓扑的描述">1 利用miniedit完成上述网络拓扑的描述</h3><h4 id="1-1_利用miniedit将各个组件：controller,_switch,_host,_link添加上去：">1.1 利用miniedit将各个组件：controller, switch, host, link添加上去：</h4><p><img src="/images/SDN/4.png" alt="picture"></p>
<h4 id="1-2_根据FatTree的定址方式为h1_~_h12分配ip地址,如为h1分配地址：">1.2 根据FatTree的定址方式为h1 ~ h12分配ip地址,如为h1分配地址：</h4><p><img src="/images/SDN/5.png" alt="picture"></p>
<h4 id="1-3_配置controller_c0的type为“remote_controller”类型:">1.3 配置controller c0的type为“remote controller”类型:</h4><p><img src="/images/SDN/6.png" alt="picture"></p>
<h4 id="1-4_“File”_-&gt;_“Save”,保存为-mn文件">1.4 “File” -&gt; “Save”,保存为.mn文件</h4><h4 id="1-5_“File”_-&gt;_“Export_Level_2_Script”，导出为-py文件">1.5 “File” -&gt; “Export Level 2 Script”，导出为.py文件</h4><h3 id="2_找到并画出生成树拓扑">2 找到并画出生成树拓扑</h3><p>为了找到当前的生成数拓扑，需要确定当前所有交换机每个端口的状态。Mininet转储命令显示端口描述每个端口的状态。这个命令写了很多的信息终端,为简单起见,我只显示相关的输出一个开关下面的输出:<br><img src="/images/SDN/7.png" alt="picture"><br>根据每个交换机的各个端口状态，可以画出如下的生成树拓扑：<br><img src="/images/SDN/8.png" alt="picture"></p>
<h3 id="3_使OpenFlow交换机表现成学习的交换机">3 使OpenFlow交换机表现成学习的交换机</h3><p>运行指令“sudo ./pox/pox.py forwarding.l2_learning openflow.spanning_tree –no-flood –hold-down log.level –DEBUG samples.pretty_log openflow.discovery host_tracker info.packet_dump”可以达到上述要求。<br>运行pingall指令得到如下结果：<br><img src="/images/SDN/9.png" alt="picture"><br>根据利用sudo ovs-ofctl dump-flows s3指令可以查看s3的流表如下：<br><img src="/images/SDN/10.png" alt="picture"></p>
<h3 id="4_模拟链路损坏的情况（至少三条链路）">4 模拟链路损坏的情况（至少三条链路）</h3><h4 id="4-1_假设s2-s4,_s5-s7,_s9-s11三条链路down掉：">4.1 假设s2-s4, s5-s7, s9-s11三条链路down掉：</h4><p><img src="/images/SDN/11.png" alt="picture"></p>
<h4 id="4-2_显示新的网络生成树拓扑">4.2 显示新的网络生成树拓扑</h4><p>在此运行上面提到的命令，得到新的网络生成树拓扑如下：<br><img src="/images/SDN/12.png" alt="picture"></p>
<h4 id="4-3_在有受损链路的网络pingall结果：">4.3 在有受损链路的网络pingall结果：</h4><p><img src="/images/SDN/13.png" alt="picture"></p>
<h4 id="4-4_查看流表">4.4 查看流表</h4><p><img src="/images/SDN/14.png" alt="picture"></p>
<h2 id="五-_实验二：Without_Controller:_implement_FatTree’s_routing_rules_with_switch_flow_rules">五. 实验二：Without Controller: implement FatTree’s routing rules with switch flow rules</h2><h3 id="1_在仿真脚本中为交换机加入合适的流表">1 在仿真脚本中为交换机加入合适的流表</h3><p>在生成的FatTree拓扑树的.py代码中，“info( ‘<em>*</em> Post configure switches and hosts\n’)”的位置下面添加构建流表的代码，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#   command_arp = r'ovs-ofctl add-flow %s "dl_type=0x806,  arp_tpa=10.%d.%d.%d, actions=output:%d"' % ('s1', 5, 6, 7, (7-2+1)%2 + 2 + 1)</span></span><br><span class="line"><span class="comment">#    print command_arp</span></span><br><span class="line"><span class="comment">#    net.get('s1').cmd(command_arp)</span></span><br><span class="line">    pods = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>)]</span><br><span class="line">    switches = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>)]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">	<span class="keyword">for</span> z <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">4</span>):</span><br><span class="line">	    switch = <span class="string">'s%d'</span> % (x*<span class="number">4</span> + z + <span class="number">1</span>)</span><br><span class="line">	    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">4</span>):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">		    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">			command_arp = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x806, arp_tpa=10.%d.%d.%d, actions=output:%d"'</span> % (switch, j, k, i, (i-<span class="number">2</span>+z)%<span class="number">2</span> + <span class="number">2</span> + <span class="number">1</span>) </span><br><span class="line">			command_ip = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x800, nw_dst=10.%d.%d.%d, actions=output:%d"'</span> % (switch, j, k, i, (i-<span class="number">2</span>+z)%<span class="number">2</span> + <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">			net.get(switch).cmd(command_arp)</span><br><span class="line">			net.get(switch).cmd(command_ip) </span><br><span class="line">	    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">		    command_arp = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x806, arp_tpa=10.%d.%d.%d, actions=output:%d"'</span> % (switch, x, i, j + <span class="number">2</span>, i + <span class="number">1</span>) </span><br><span class="line">		    command_ip = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x800, nw_dst=10.%d.%d.%d, actions=output:%d"'</span> % (switch, x, i, j + <span class="number">2</span>, i + <span class="number">1</span>)</span><br><span class="line">		    net.get(switch).cmd(command_arp)</span><br><span class="line">		    net.get(switch).cmd(command_ip)</span><br><span class="line">	<span class="keyword">for</span> z <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">	    switch = <span class="string">'s%d'</span> % (x*<span class="number">4</span> + z + <span class="number">1</span>)</span><br><span class="line">	    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">4</span>):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">		    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">		        command_arp = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x806, arp_tpa=10.%d.%d.%d, actions=output:%d"'</span> % (switch, j, k, i, (i-<span class="number">2</span>+z)%<span class="number">2</span> + <span class="number">2</span> + <span class="number">1</span>) </span><br><span class="line">		        command_ip = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x800, nw_dst=10.%d.%d.%d, actions=output:%d"'</span> % (switch, j, k, i, (i-<span class="number">2</span>+z)%<span class="number">2</span> + <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">			net.get(switch).cmd(command_arp)</span><br><span class="line">			net.get(switch).cmd(command_ip)</span><br><span class="line">	    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">	        command_arp = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x806, arp_tpa=10.%d.%d.%d, actions=output:%d"'</span> % (switch, x, z, (i+<span class="number">2</span>), i + <span class="number">1</span>)  </span><br><span class="line">	        command_ip = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x800, nw_dst=10.%d.%d.%d, actions=output:%d"'</span> % (switch, x, z, (i+<span class="number">2</span>), i + <span class="number">1</span>)</span><br><span class="line">		net.get(switch).cmd(command_arp)</span><br><span class="line">		net.get(switch).cmd(command_ip)</span><br><span class="line">    </span><br><span class="line">    switches = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">17</span>,<span class="number">21</span>)]</span><br><span class="line">    <span class="keyword">for</span> z <span class="keyword">in</span> range(<span class="number">17</span>,<span class="number">21</span>):</span><br><span class="line">	switch = <span class="string">'s%d'</span> % z</span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):</span><br><span class="line">	    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">		<span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">4</span>):</span><br><span class="line">    	            command_arp = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x806, arp_tpa=10.%d.%d.%d, actions=output:%d"'</span> % (switch, x, j, k, x + <span class="number">1</span>) </span><br><span class="line">	            command_ip = <span class="string">r'ovs-ofctl add-flow %s "dl_type=0x800, nw_dst=10.%d.%d.%d, actions=output:%d"'</span> % (switch, x, j, k, x + <span class="number">1</span>)</span><br><span class="line">		    net.get(switch).cmd(command_arp)</span><br><span class="line">		    net.get(switch).cmd(command_ip)</span><br></pre></td></tr></table></figure></p>
<h3 id="2_用pingall指令测试路由规则">2 用pingall指令测试路由规则</h3><p><img src="/images/SDN/15.png" alt="picture"><br>结果显示，主机之间能够完全Ping通。</p>
<h3 id="3_发证明FatTree中的流量通过流表被平均分配">3 发证明FatTree中的流量通过流表被平均分配</h3><p>通过iperf指令来验证处于同一个pod，不同pod的主机之间的流量数据：<br><img src="/images/SDN/16.png" alt="picture"><br>绘制成图标如下：<br><img src="/images/SDN/17.png" alt="picture"><br>数据表明，h1到其他的主机之间的上行、下行带宽基本都在19Gbits左右，比较平均。</p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2016/01/24/advices-for-2016/" itemprop="url">
                  advice && list for 2016
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2016-01-24T19:30:02+08:00" content="2016-01-24">
              2016-01-24
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h2 id="关于生活">关于生活</h2><h3 id="1-for_sports">1.for sports</h3><ul>
<li>be professional:无论是健身，跑步，还是游泳，都应该尽量专业，以达到高效、安全的目的；这方面可以从知乎、quora以及相关的论坛找到相关的专业知识。</li>
<li>try to be regular: 虽然有各种各样的事情来打乱计划，但是应该尽量保持有规律的运动，每个星期尽量能偶健身一到两次，游泳一次。</li>
<li>try to break the bottleneck:尽量有意识的通过较为专业的训练来突破自己的界限，走出身体的舒适区，尝试那些没有试过的分支项目。</li>
</ul>
<h3 id="2-for_regular_life">2.for regular life</h3><ul>
<li>don’t judge: cited from 《The Great Gatsby》  <blockquote>
<p>‘Whenever you feel like criticizing any one,’ he told me,’just remember that all the people in this world haven’t<br>had the advantages that you’ve had.’</p>
</blockquote>
</li>
<li>注意健康饮食： 不吃夜宵，早餐尽量吃高蛋白事物，尽量吃低脂食物。</li>
<li>规律睡眠：尽量在十二点之前入睡，八点之前起床。</li>
<li>敏锐观察，不断自省：留心生活中的人和事，理解其中的小规律(规矩)，并不断取其精华，去其糟粕，不断充实、完善自己。</li>
<li>知行合一：“知是行的主意，行是知的工夫；知是行之始，行是知之成” -王守仁</li>
</ul>
<h2 id="关于学习">关于学习</h2><ul>
<li>完成实验室的项目，争取在计划时间内成功交付<ul>
<li>能找到自己做的部分里有价值的东西，并提交开源代码及报告</li>
</ul>
</li>
<li>及时记下自己在平时脑子里冒出来的idea, 并花一定的时间分析它的可行性和价值<ul>
<li>idea is important, so track it down</li>
</ul>
</li>
<li>及早确定研究方向，以便能够及早做出成果，当然能发出一到两篇论文就更好了</li>
<li>及时总结记录，好记性不如烂笔头</li>
</ul>
<p><em>to be continued</em></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2016/01/24/2015总结/" itemprop="url">
                  2015总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2016-01-24T09:40:19+08:00" content="2016-01-24">
              2016-01-24
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h2 id="时间轴">时间轴</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2015年应该可以从保研之后开始算起；但是我觉得推免应该可以说是对我四年成绩的一次总体体现，且其中出现的各种意外也可以说是给我狠狠地上了几堂课，还是值得一说的，保研（推免）这个事可以说是从2014年七月份开始算起的，那个时候其实也没有想的那么多事情，但是Tisen说有时间就应该到处看看，见识一下外面的世界，对比一下就知道自己和别人的差距了，顿时觉得十分在理（在这里要特别说一下Tsien，真的是一位有远见，有计划，执行力强的牛人，膜拜ing），然后就是在新老校区之间跑来跑去，打成绩单、荣誉证书、推荐信等相关的东西。搞定这些东西，剩下的就是选择学校了，当时时有很多的合适的学校的，当时因为自己的固执和偏见只选择了里家里近的几所学校，会过来看自己的眼光还是太局限了，另外一个就是担心新的政策的施行问题，也错过了另一些学校的暑期实习，不得不说还是非常遗憾的。到了九十月份的时候基本上很多东西都确定了，不过在这个时候还是犯了提前计划不足，眼光局限的问题，这些方面都是我以后需要注意、改进、提高的提防的方面，但是最后的结果还是蛮令人满意的，非常荣幸能够来到科大继续我的研究生学习。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后就是11月份的考驾照，不得不说考驾照真的是一件熬心的事，天天早起去排队，还要受教练的气，熬了几个月，磕磕绊绊的算是考完驾照了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再后面就是三月份的开学了，开学过后就直接来科大准备毕业课设了，毕业设计是由师兄带着做的，这个毕业设计做的自己并不是非常满意，主要是后面没有做成一个可用，可以展示的model，另外就是还有自己的一些想法没有验证和实现，如果要要给自己的毕业设计打一个分数的话，我觉得差不多70分吧，毕业设计的经历给了我几个指导：</p>
<ol>
<li>多和师兄和老师交流，他们的经验可以让自己少走很多的弯路</li>
<li>要带着讨论的态度看待别人的论文，不能拿来主义，应取其精华，去其糟粕</li>
<li>在进行专业性的演讲时应该充分考虑到听者的专业层次</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在后面就是开学的事情了，上学期的课其实还有很多蛮有意思的，首先要说的是密码学，原本我是不喜欢密码学这个方向的，觉得都是一堆的数论知识很无聊，但是上了课就觉得老师讲的蛮有意思的，唯一的缺憾就是没有什么相关的project，感觉有点浮在表面上；下一个我喜欢的课就是老王的导师教的高级计算机网络，虽然上课的时候并没有听多少，但是project做的很开心，也学习了很多，像目前研究的比较热的SDN, 新型网络架构等都可以说让我打开眼界；另外一门组合数学的课尽是理论，到目前为止我还没看到它对与计算机科学有什么用的啊，看来还是我的level太低了；</p>
<h2 id="生活方面">生活方面</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于生活方面，首先是运动方面，这一年的各种运动也都有一直在做，但是因为各种各样的原因总是断断续续的，一直不能持续的训练，其实这个是可以规律的进行的，只是自己的毅力还是不够吧，想想当初之所以选择科大，健身房也是吸引我的一个重要因素，不能因为生活，学习中的琐事就放弃了这么nice的健身氛围。另外就是游泳，由于办了游泳卡，去游泳馆的次数还是蛮多的，只用四五次就学会了蛙泳，彻底告别狗刨，但是也是因为自己的注意，导致耳朵进了水，最严重的时候几乎都听不到声音，跟失聪了一样，到最后不得不进行鼓膜穿刺才感觉好一点。所以以后要注意在运动的时候要十分注意进行防护，以免给自己造成不必要的疼苦。关于跑步，这一年总共也就跑了几十次吧，不是很多，特别是来到科大后，因为空气质量的原因就跑得比较少了，自己在跑步机上跑又会感觉自己的脚掌内部非常疼。我想这一切都是因为自己的不专业导致的，所以说以后在运动中，一定要科学地来进行，努力地做到专业，让自己得到有效且安全的提升。</p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2016/01/03/Spark-SQL对多数据源的支持/" itemprop="url">
                  Spark SQL对多数据源的支持
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2016-01-03T19:08:17+08:00" content="2016-01-03">
              2016-01-03
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h2 id="1-_什么是Spark_SQL?">1. 什么是Spark SQL?</h2><p>Spark SQL是一个针对结构化数据的Spark框架，它提供了一个叫DataFrames的编程抽象，而且还可以扮演分布式SQL查询引擎的角色。</p>
<h3 id="1-1_Spark_SQL提供的数据抽象:DataFrame">1.1 Spark SQL提供的数据抽象:DataFrame</h3><p>一个DataFrame是一个列式数据构成的数据集合。它概念上等同于关系数据库中的一张表或者Python/R语言中的框架，但是在底层有更多的优化。DataFrame可以通过广泛的数据源来构建，例如：结构化的数据文件、Hive中的表、外部的数据库，或者已经存在的RDD。</p>
<blockquote>
<p>关于Spark SQL更多的介绍，可见<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#creating-dataframes" target="_blank" rel="external">Spark SQL and DataFrame Guide</a></p>
</blockquote>
<h2 id="2-_支持JSON数据类型">2. 支持JSON数据类型</h2><p>以下关于Spark SQL对JSON文件的处理过程同样适用与其他各种类型的外部数据源，DataFrame数据结构提供了统一的数据抽象。</p>
<h3 id="2-1_开始：SQLContext">2.1 开始：SQLContext</h3><p>Spark SQL的入口是SQLContext类（或者是它的子类）。为了创建SQLContext，只需要SparkContext。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sc</span>:</span> <span class="type">SparkContext</span> <span class="comment">// An existing SparkContext.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br><span class="line"></span><br><span class="line"><span class="comment">// this is used to implicitly convert an RDD to a DataFrame.</span></span><br><span class="line"><span class="keyword">import</span> sqlContext.implicits._</span><br></pre></td></tr></table></figure></p>
<h3 id="2-2_创建DataFrame">2.2 创建DataFrame</h3><p>利用SQLContext，应用可以从一个已存在的RDD（需要知道Schema）、Hive Table、各种外部数据源来创建DataFrame。<br>下面是基于一个JSON文件的内容创建一个DataFrame：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sc</span>:</span> <span class="type">SparkContext</span> <span class="comment">// An existing SparkContext.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">df</span> =</span> sqlContext.read.json(<span class="string">"examples/src/main/resources/people.json"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Displays the content of the DataFrame to stdout</span></span><br><span class="line">df.show()</span><br></pre></td></tr></table></figure></p>
<h3 id="2-3_DataFrame的操作">2.3 DataFrame的操作</h3><p>DataFrame以Scala, Java, Python语言为结构化的数据操作提供了域限定性语言。<br>下面展示了使用DataFrame进行一些基本的结构化数据操作：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sc</span>:</span> <span class="type">SparkContext</span> <span class="comment">// An existing SparkContext.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the DataFrame</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">df</span> =</span> sqlContext.read.json(<span class="string">"examples/src/main/resources/people.json"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Show the content of the DataFrame</span></span><br><span class="line">df.show()</span><br><span class="line"><span class="comment">// age  name</span></span><br><span class="line"><span class="comment">// null Michael</span></span><br><span class="line"><span class="comment">// 30   Andy</span></span><br><span class="line"><span class="comment">// 19   Justin</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Print the schema in a tree format</span></span><br><span class="line">df.printSchema()</span><br><span class="line"><span class="comment">// root</span></span><br><span class="line"><span class="comment">// |-- age: long (nullable = true)</span></span><br><span class="line"><span class="comment">// |-- name: string (nullable = true)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Select only the "name" column</span></span><br><span class="line">df.select(<span class="string">"name"</span>).show()</span><br><span class="line"><span class="comment">// name</span></span><br><span class="line"><span class="comment">// Michael</span></span><br><span class="line"><span class="comment">// Andy</span></span><br><span class="line"><span class="comment">// Justin</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Select everybody, but increment the age by 1</span></span><br><span class="line">df.select(df(<span class="string">"name"</span>), df(<span class="string">"age"</span>) + <span class="number">1</span>).show()</span><br><span class="line"><span class="comment">// name    (age + 1)</span></span><br><span class="line"><span class="comment">// Michael null</span></span><br><span class="line"><span class="comment">// Andy    31</span></span><br><span class="line"><span class="comment">// Justin  20</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Select people older than 21</span></span><br><span class="line">df.filter(df(<span class="string">"age"</span>) &gt; <span class="number">21</span>).show()</span><br><span class="line"><span class="comment">// age name</span></span><br><span class="line"><span class="comment">// 30  Andy</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Count people by age</span></span><br><span class="line">df.groupBy(<span class="string">"age"</span>).count().show()</span><br><span class="line"><span class="comment">// age  count</span></span><br><span class="line"><span class="comment">// null 1</span></span><br><span class="line"><span class="comment">// 19   1</span></span><br><span class="line"><span class="comment">// 30   1</span></span><br></pre></td></tr></table></figure></p>
<p>关于DataFrame的全部的操作列表，可见<a href="http://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrame.html" target="_blank" rel="external">the API Documentation</a>。<br>除了上面这些简单的列操作已经表达式操作，DataFrame还有一个丰富的库来支持字符串操作，数值运算等。完整的列表可见<a href="http://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/functions.html" target="_blank" rel="external">DataFrame Function Reference</a>。</p>
<h3 id="2-4_运行SQL查询语句">2.4 运行SQL查询语句</h3><p>SQLContext类中的sql函数可以使应用程序化的运行SQL 查询语句，并且以DataFrame的形式返回。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> ...  <span class="comment">// An existing SQLContext</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">df</span> =</span> sqlContext.sql(<span class="string">"SELECT * FROM table"</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-_解释RDD">3. 解释RDD</h2><p>Spark SQL支持两种不同的方法将现有的RDD转化为DataFrames。第一种方法是使用反射来导出一个RDD的schema。写spark的应用程序时，在已知数据的schema的时候，反射的方法可以帮助写出更简介的代码。<br>第二种方法，通过一个编程接口（这个编程接口可以帮助你构建一个schema并且应用到一个已经存在的RDD上）。</p>
<h3 id="3-1_利用反射来导出Schema">3.1 利用反射来导出Schema</h3><p>Spark SQL 的scala接口支持将一个包含类类型(case class)的RDD转换成DataFrame的接口。类类型(case class)定义了表的schema。通过反射机制来读取类类型的参数，其将成为列名(column)，类类型(case class)也支持嵌套以及复杂的数据类型，像Sequence 和 Array。这种RDD可以被隐式地转换成DataFrame并转换成表，然后就可以执行SQL操作。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sc is an existing SparkContext.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br><span class="line"><span class="comment">// this is used to implicitly convert an RDD to a DataFrame.</span></span><br><span class="line"><span class="keyword">import</span> sqlContext.implicits._</span><br><span class="line"></span><br><span class="line"><span class="comment">// Define the schema using a case class.</span></span><br><span class="line"><span class="comment">// Note: Case classes in Scala 2.10 can support only up to 22 fields. To work around this limit,</span></span><br><span class="line"><span class="comment">// you can use custom classes that implement the Product interface.</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(</span>name: <span class="type">String</span>, age: <span class="type">Int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create an RDD of Person objects and register it as a table.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">people</span> =</span> sc.textFile(<span class="string">"examples/src/main/resources/people.txt"</span>).map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Person</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim.toInt)).toDF()</span><br><span class="line">people.registerTempTable(<span class="string">"people"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL statements can be run by using the sql methods provided by sqlContext.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">teenagers</span> =</span> sqlContext.sql(<span class="string">"SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations.</span></span><br><span class="line"><span class="comment">// The columns of a row in the result can be accessed by field index:</span></span><br><span class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t(<span class="number">0</span>)).collect().foreach(println)</span><br><span class="line"></span><br><span class="line"><span class="comment">// or by field name:</span></span><br><span class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t.getAs[<span class="type">String</span>](<span class="string">"name"</span>)).collect().foreach(println)</span><br><span class="line"></span><br><span class="line"><span class="comment">// row.getValuesMap[T] retrieves multiple columns at once into a Map[String, T]</span></span><br><span class="line">teenagers.map(_.getValuesMap[<span class="type">Any</span>](<span class="type">List</span>(<span class="string">"name"</span>, <span class="string">"age"</span>))).collect().foreach(println)</span><br><span class="line"><span class="comment">// Map("name" -&gt; "Justin", "age" -&gt; 19)</span></span><br></pre></td></tr></table></figure></p>
<h3 id="3-2_利用编程接口来得出Schema">3.2 利用编程接口来得出Schema</h3><p>当一个case class类没有事先定义的时候（比如说，一个记录的结构被编码进了一个字符串中，或者是一个文本集，它针对不同的用户可能解析不同的field），则一个DataFrame可以通过下面三步构造成功：</p>
<ol>
<li>从一个存在RDD中构造行RDD（RDD of Rows）；</li>
<li>从步骤1中每行对应的结构类型中构造Schema；</li>
<li>通过CreateDataFrame方法将每行的Schema(schema of rows)应用到行RDD中；</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sc is an existing SparkContext.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create an RDD</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">people</span> =</span> sc.textFile(<span class="string">"examples/src/main/resources/people.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// The schema is encoded in a string</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">schemaString</span> =</span> <span class="string">"name age"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Import Row.</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Import Spark SQL data types</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>,<span class="type">StructField</span>,<span class="type">StringType</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Generate the schema based on the string of schema</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">schema</span> =</span></span><br><span class="line">  <span class="type">StructType</span>(</span><br><span class="line">    schemaString.split(<span class="string">" "</span>).map(fieldName =&gt; <span class="type">StructField</span>(fieldName, <span class="type">StringType</span>, <span class="literal">true</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert records of the RDD (people) to Rows.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">rowRDD</span> =</span> people.map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Row</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Apply the schema to the RDD.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">peopleDataFrame</span> =</span> sqlContext.createDataFrame(rowRDD, schema)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Register the DataFrames as a table.</span></span><br><span class="line">peopleDataFrame.registerTempTable(<span class="string">"people"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL statements can be run by using the sql methods provided by sqlContext.</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">results</span> =</span> sqlContext.sql(<span class="string">"SELECT name FROM people"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations.</span></span><br><span class="line"><span class="comment">// The columns of a row in the result can be accessed by field index or by field name.</span></span><br><span class="line">results.map(t =&gt; <span class="string">"Name: "</span> + t(<span class="number">0</span>)).collect().foreach(println)</span><br></pre></td></tr></table></figure>
<h2 id="4-_支持MySQL等关系型数据库">4. 支持MySQL等关系型数据库</h2><p>对于spark sql支持mysql数据库，只需要将mysql-connector-java-x.x.x-bin.jar加入到spark的系统路径中。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> jdbcDF = sqlContext.read.format(<span class="string">"jdbc"</span>).options(<span class="type">Map</span>(<span class="string">"url"</span> -&gt; <span class="string">"jdbc:mysql://210.45.64.92:3306/weibo_prediction?user=root&amp;password=123456"</span>,<span class="string">"dbtable"</span> -&gt; <span class="string">"weibo_train"</span> ).load();</span><br><span class="line">jdbcDF.registerTempTable(<span class="string">"weibo_train"</span>);</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这一章的引用：<br>1.<a href="http://stackoverflow.com/questions/29196457/how-to-use-spark-dataframe-with-mysql" target="_blank" rel="external">stackoverflow</a><br>2.<a href="http://www.infoobjects.com/spark-dataframes-and-jdbc/" target="_blank" rel="external">Spark: DataFrame and JDBC</a> </p>
</blockquote>
<h2 id="5-_支持MangoDB等非关系型数据库">5. 支持MangoDB等非关系型数据库</h2><h3 id="5-1_最原始的方法">5.1 最原始的方法</h3><p>类似RDD，目前spark sql对mongoDB的支持，需要采用利用saprkContext接口将mongodb读取成RDD，然后利用第三节的方法来解释RDD，得到DataFrame。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.examples </span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkContext</span>, <span class="type">SparkConf</span>&#125; </span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span> </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.<span class="type">Configuration</span> </span><br><span class="line"><span class="keyword">import</span> org.bson.<span class="type">BSONObject</span> </span><br><span class="line"><span class="keyword">import</span> com.mongodb.hadoop.&#123;<span class="type">MongoInputFormat</span>, <span class="type">BSONFileInputFormat</span>&#125; </span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql </span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DataMigrator</span> &#123;</span> </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(</span>args: <span class="type">Array</span>[<span class="type">String</span>])</span><br><span class="line">    &#123; </span><br><span class="line">        <span class="function"><span class="keyword">val</span> <span class="title">conf</span> =</span> <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"Migration    App"</span>).setMaster(<span class="string">"local"</span>) </span><br><span class="line">        <span class="function"><span class="keyword">val</span> <span class="title">sc</span> =</span> <span class="keyword">new</span> <span class="type">SparkContext</span>(conf) </span><br><span class="line">        <span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> <span class="keyword">new</span> <span class="type">SQLContext</span>(sc) </span><br><span class="line"></span><br><span class="line">        <span class="comment">// Import statement to implicitly convert an RDD to a DataFrame </span></span><br><span class="line">        <span class="keyword">import</span> sqlContext.implicits._ </span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">val</span> <span class="title">mongoConfig</span> =</span> <span class="keyword">new</span> <span class="type">Configuration</span>() </span><br><span class="line">        mongoConfig.set(<span class="string">"mongo.input.uri"</span>,   <span class="string">"mongodb://localhost:27017/mongosails4.case"</span>) </span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">val</span> <span class="title">mongoRDD</span> =</span> sc.newAPIHadoopRDD(mongoConfig, classOf[<span class="type">MongoInputFormat</span>], classOf[<span class="type">Object</span>], classOf[<span class="type">BSONObject</span>]);     </span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">val</span> <span class="title">count</span> =</span> countsRDD.count()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// the count value is aprox 100,000 </span></span><br><span class="line">        println(<span class="string">"================ PRINTING ====================="</span>) </span><br><span class="line">        println(s<span class="string">"ROW COUNT IS $count"</span>) </span><br><span class="line">        println(<span class="string">"================ PRINTING ====================="</span>) </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在得到一个RDD后需要</p>
<ol>
<li><p>为你的RDD 创建一个case class</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Data</span>(</span>x: <span class="type">Int</span>, s: <span class="type">String</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>将rdd中的值映射到case class中的实例</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">dataRDD</span> =</span> mongoRDD.values.map &#123; obj =&gt; <span class="type">Data</span>(obj.get(<span class="string">"x"</span>), obj.get(<span class="string">"s"</span>)) &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>利用RDD data, 通过sqlcontext创建dataframe</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">myDF</span> =</span> sqlContext.createDataFrame(dataRDD)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="5-2_更好的解决方案:Stratio">5.2 更好的解决方案:Stratio</h3><p>目前开源api Stratio可以很好的支持 Mongodb，免去了应用程序定义case class的繁琐过程。<br>例子如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">mcInputBuilder</span> =</span> <span class="type">MongodbConfigBuilder</span>(<span class="type">Map</span>(<span class="type">Host</span> -&gt; <span class="type">List</span>(<span class="string">"localhost:27017"</span>), <span class="type">Database</span> -&gt; <span class="string">"marketdata"</span>, <span class="type">Collection</span> -&gt; <span class="string">"minbars"</span>, <span class="type">SamplingRatio</span> -&gt; <span class="number">1.0</span>, <span class="type">WriteConcern</span> -&gt; <span class="type">MongodbWriteConcern</span>.<span class="type">Normal</span>))</span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">readConfig</span> =</span> mcInputBuilder.build()</span><br><span class="line"></span><br><span class="line"><span class="comment">//HiveContext uses Hive's SQL parser with a superset of features of SQLContext so I used that one</span></span><br><span class="line"><span class="comment">//	See http://spark.apache.org/docs/1.4.0/sql-programming-guide.html#starting-point-sqlcontext for more info</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">sqlContext</span> =</span> <span class="keyword">new</span> <span class="type">HiveContext</span>(sc)			<span class="comment">//sc is already defined as a SparkContext by the shell</span></span><br><span class="line"><span class="function"><span class="keyword">val</span> <span class="title">dfOneMin</span> =</span> sqlContext.fromMongoDB(readConfig) 	<span class="comment">//set up the MongoDB collection to read from as a DataFrame</span></span><br><span class="line">dfOneMin.registerTempTable(<span class="string">"minbars"</span>)			<span class="comment">//make the table minbars available to the SQL expressions later</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这一章节的相关引用<br>1.<a href="https://github.com/Stratio/spark-mongodb" target="_blank" rel="external">Stratio</a><br>2.<a href="http://stackoverflow.com/questions/31838468/save-mongodb-data-to-parquet-file-format-using-apache-spark" target="_blank" rel="external">Save MongoDB data to parquet file format using Apache Spark</a></p>
</blockquote>
<h2 id="6-_支持HBase">6. 支持HBase</h2>
            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2015/10/10/解忧杂货店/" itemprop="url">
                  《解忧杂货店》
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2015-10-10T20:25:04+08:00" content="2015-10-10">
              2015-10-10
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <blockquote>
<p>如果把找我咨询的人比喻成迷途的羔羊，通常他们手上都有地图，却没有去看，或是不知道自己目前的位置。但是我相信你不属于这两种情况。你的地图是一张白纸，所以即使想决定目的地，也不知道路在哪里。地图是一张白纸，这当然很伤脑筋。任何人都会不知所措。可是换个角度来看，正因为是一张白纸，才可以随心所欲地描绘地图。一切全在你自己。对你来说，一切都是自由的，在你面前是无限的可能。这可是很棒的事情啊。我衷心祈祷你可以相信自己，无悔地燃烧自己的人生。</p>
</blockquote>
<p>一间小小的杂货店，将几个处在人生岔路口的年轻人纠缠在一起。三个自称为“社会的渣滓”的无业小偷；因为男友身患癌症，在参加奥运会集训和陪伴男友的选择中迷茫的女运动员；在音乐梦想和继承祖传鱼店之间徘徊的音乐人；在当陪酒小姐赚快钱和独自开店创业的矛盾中挣扎的“迷途的小狗”…他们的迷茫好似互不相关，毫无关联，但是因为“解忧杂货店”的信箱和孤儿院“丸光园”被紧紧地联系在一起，最终，他们每个人都找到了补住内心漏洞的方法，找到了各自的人生方向，也深深地感受到了这个世界的善意和温暖。翔太、敦也、幸平是三个自称为“社会的渣滓”的社会青年，他们在进行一次绑架后不经意间躲到了浪矢老爷爷家杂货店里，却无意间收到了来自过去的咨询信，因为这件奇妙的房子，将他们和过去的几个人联系在一起，努力训练的击剑选手月兔因为他们的信最终坚持了自己的决定，即便他们好像不是因为他们；在隔着门听完那曲著名的《重生》后恍然大悟，将“丸光园”失火、慰问演出的歌手、以及后来成为著名歌手的孤儿小芹、、、这一切都联系在一起，因此鼓励那位徘徊的鱼店音乐人要坚持下去，说出“你对音乐的执着追求，绝不是白白付出”的话；指导“迷途的小狗”学习房地产、证券交易等方面的知识并告诉她最好的进军市场的时间；却发现自己绑架的那个女人就是曾经知道的“迷途的小狗”，因为“迷途的小狗”的感谢信而迷途知返、、、每个人的故事都像河面的独立涟漪一样，不可思议的交汇在一起，形成奇妙而和谐的共振。<br>    下面这段话引用自豆瓣，同时也代表了我读这本书的感受：</p>
<blockquote>
<p>“《解忧杂货店》缜密的故事架构与精妙的情节设计，让人不得不叹服：“才华”这东西，真是与生俱来啊﹗更重要的是，东野圭吾在洞悉世情与人心之余，愿以善意回应，让人明白在这破洞不断的世界里，仍有人竭尽所能在用心填补，知道每个人活在这世上都不容易，都有各自的难题，都有难以启齿而感觉被世界孤立的那一刻，也明白人们需要的未必是如何解决的答案，而是那一刻有人愿意认真倾听，且愿意与孤绝的自己同在。这就是《解忧杂货店》的精神，也是我心中书写价值的所在。 ”</p>
</blockquote>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2015/09/04/Apache-Spark-利用Intellij-IDEA开发Spark程序/" itemprop="url">
                  Apache-Spark:利用Intellij IDEA开发Spark程序
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2015-09-04T16:29:50+08:00" content="2015-09-04">
              2015-09-04
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h2 id="1-_准备工作">1. 准备工作</h2><ol>
<li>安装JDK7</li>
<li>安装Scala 2.10.x（因为实验室的spark集群是1.1.1版本的，它指定需要Scala 2.10.x版本）</li>
<li>Intellij IDEA Community Edition 14.1.4, 在安装的时候可以安装Scala插件，后面就不需要安装啦。</li>
</ol>
<h2 id="2-_WordCount例子">2. WordCount例子</h2><h3 id="2-1_新建Maven工程">2.1 新建Maven工程</h3><p>在intellij IDEA中创建Maven project, “File”-&gt;”New”-&gt;”Project”-&gt;”Maven”，填入相关信息，如下：<br><img src="/images/Spark/1.png" alt="picture"></p>
<h2 id="2-2_编写pom-xml文件">2.2 编写pom.xml文件</h2><p>在pom.xml文件加入依赖和插件：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spark-core_2.10<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.1.1<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="title">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">build</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="2-3_导入相关的包">2.3 导入相关的包</h2><h3 id="2-3-1_导入spark的JAR包">2.3.1 导入spark的JAR包</h3><p>选择“File”–&gt; “project structure” –&gt; “Libraries”，选择“+”，将spark-hadoop 对应的包导入，比如导入spark-examples-1.1.1-hadoop2.3.0.jar（它在Spark的安装目录的lib文件夹下）。<br><img src="/images/Spark/2.png" alt="picture"></p>
<h3 id="2-3-2_导入scala库">2.3.2 导入scala库</h3><p>选择“File”–&gt; “project structure” –&gt; “Modules”，选择“+”，会自动出现Scala的库选项，添加,“Apply”-&gt;“OK”。<br><img src="/images/Spark/4.png" alt="picture"></p>
<h3 id="2-4_新建WordCount_Java类">2.4 新建WordCount Java类</h3><p>在src/main/java下新建Java类，取名“WordCount”，添加如下代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function2;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.PairFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.regex.Pattern;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern SPACE = Pattern.compile(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//System.setProperty("hadoop.home.dir", "c:\\winutil\\");</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (args.length &lt; <span class="number">1</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"Usage: JavaWordCount &lt;file&gt;"</span>);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> begin = System.currentTimeMillis();</span><br><span class="line">        SparkConf sparkConf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"WordCount"</span>);</span><br><span class="line">        sparkConf.setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext ctx = <span class="keyword">new</span> JavaSparkContext(sparkConf);</span><br><span class="line">        JavaRDD&lt;String&gt; lines = ctx.textFile(args[<span class="number">0</span>], <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;String&gt; words = lines.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="annotation">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(SPACE.split(s));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; ones = words.mapToPair(<span class="keyword">new</span> PairFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="annotation">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Tuple2&lt;String, Integer&gt; call(String s) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(s, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey(<span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">            <span class="annotation">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer i1, Integer i2)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> i1 + i2;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect();</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;?,?&gt; tuple : output) &#123;</span><br><span class="line">            System.out.println(tuple._1() + <span class="string">": "</span> + tuple._2());</span><br><span class="line">        &#125;</span><br><span class="line">        ctx.stop();</span><br><span class="line">        <span class="keyword">long</span> end = System.currentTimeMillis() - begin;</span><br><span class="line">        System.out.println(<span class="string">"wasting time:"</span>+end+<span class="string">"ms"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="2-5_配置运行">2.5 配置运行</h3><p>点击“Run”-&gt;“Run”设置相关参数，如下：<br><img src="/images/Spark/3.png" alt="picture"><br>“Apply”-&gt;“Run”。<br>运行结果如下图所示：<br><img src="/images/Spark/5.png" alt="picture"></p>
<h2 id="3-_注意：">3. 注意：</h2><ol>
<li>在Windows下运行需要Spark需要hadoop的插件包：<a href="http://jingyan.baidu.com/article/d3b74d64cc2a0c1f77e609d2.html" target="_blank" rel="external">help</a></li>
<li>如果出现“ A master URL must be set in your configuration”错误：参见<a href="http://www.ithao123.cn/content-514918.html" target="_blank" rel="external">help1</a></li>
</ol>
<h2 id="4-_参考资料">4. 参考资料</h2><ol>
<li><a href="http://spark.apache.org/" target="_blank" rel="external">Spark</a>;</li>
<li><a href="https://www.jetbrains.com/idea/download/" target="_blank" rel="external">intellij IDEA</a></li>
<li><a href="http://hadoop.apache.org/" target="_blank" rel="external">Hadoop</a></li>
</ol>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2015/08/28/暑期总结/" itemprop="url">
                  暑期总结（2015）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2015-08-28T17:30:26+08:00" content="2015-08-28">
              2015-08-28
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>本科毕业典礼一完事，就早早地被学校赶回家了，非常感谢胖子和知雨兄最后的送行，感觉在大学四年能有几个志同道合的小伙伴还是一件蛮幸运的事 o(∩_∩)o 。然后就好好的在家里躺尸了几天，吃了几天妈妈吃的饭菜，就开始整理大学四年的一些记忆了，整理了几天，发现自己果然是一个拍照狂魔啊，好的差的拍了几万张，一张一张的整理了两三天，终于挑好了一些自己觉得满意的几百张照片。整理了将近两个星期，终于把这些杂七杂八的东西整理完了。接下来就要好好考虑该干嘛了，正好又买了Kindle,我就看了一些自己感兴趣的书籍，现一一列出：</p>
<h2 id="1-演讲之禅">1.<a href="http://book.douban.com/subject/4760725/" target="_blank" rel="external">演讲之禅</a></h2><p>这是一本介绍关于演讲技巧的书籍，作者是一位技术演讲家，常年在各大互联网公司之间进行技术性的演讲。作者根据他多年的演讲经历总结了一些十分实用的演讲技巧。看完后，我觉得这是一本十分使用的书籍，书中的很多技巧无论对于小型演讲还是大型演讲都是十分有效的。</p>
<h2 id="2-平凡的世界">2.<a href="http://book.douban.com/subject/6835758/" target="_blank" rel="external">平凡的世界</a></h2><p>无需多言，经典中的经典，作者平实的语言深刻形象地刻画了几个人物形象，尤为佩服孙少平和孙少安，他们都是铁骨铮铮的汉子！</p>
<h2 id="3-明朝那些事儿">3.<a href="http://book.douban.com/subject/7163250/" target="_blank" rel="external">明朝那些事儿</a></h2><p>一本通俗有趣的历史科普书，本来以前也完整地看过一偏，但是意犹未尽，于是又看了一偏，记得看得第一遍的时候，只觉得里面的历史故事都蛮有趣的，但是这次再读的时候，我感受到了更多的东西，感受到名族大义与一己私利，忠诚与背叛，理性和感性，永垂不朽与遗臭万年，阿谀奉承与刚正不阿…。</p>
<h2 id="4-深入理解Java虚拟机">4.<a href="http://book.douban.com/subject/6522893/" target="_blank" rel="external">深入理解Java虚拟机</a></h2><p>这是我读过的为数不多的国人写过的好的技术书籍之一。书中对于JVM的内存管理系统，执行子系统，程序编译和优化等内容都有很详细的介绍。我觉得对于想从事Java编程的人都应该读一下这本书。值得再看一遍。</p>
<h2 id="5-Effective_Java">5.<a href="http://book.douban.com/subject/3360807/" target="_blank" rel="external">Effective Java</a></h2><p>本书介绍了在Java编程中78条极具实用价值的经验规则，这些经验规则涵盖了大多数开发人员每天所面临的问题的解决方案。但是以现在我的编程经验对于里面一些内容还不能理解，看来还要加强学习实践。这是一本值得多看几遍的书籍。</p>
<h2 id="6-美国纽约摄影学院摄影教材">6.<a href="http://book.douban.com/subject/1007928/" target="_blank" rel="external">美国纽约摄影学院摄影教材</a></h2><p>觉得自己既然这么喜欢拍照，应该加强一下自己的拍照技巧，然后就在网上找到这本书，不得不说，对于喜欢摄影的人来说，这真的是一本非常合适的入门书籍，但是我只看了60%，因为暂时还没有买单反的计划 orz,就没有再看下去的动力了。</p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2015/08/06/deep-into-JVM-6/" itemprop="url">
                  深入理解JVM(6)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2015-08-06T21:09:21+08:00" content="2015-08-06">
              2015-08-06
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>这是我写的关于《深入理解Java虚拟机：JVM高级特性与最佳实战（第2版）》的读书笔记。</p>
<h1 id="早期（编译期）优化">早期（编译期）优化</h1><h2 id="概述">概述</h2><ul>
<li>前端编译器：Sun的Javac、 Eclipse JDT中的增量编译器</li>
<li>JIT编译器： HotSpot VM的C1、C2编译器</li>
<li>AOT编译器： GNU Compiler for Java<br>虚拟机设计团队把对性能的优化集中到后端的即时编译器中，这样能够保证让那些不是由Javac产生的Class文件也能同样能享受到编译器优化所带来的好处。</li>
</ul>
<h2 id="Javac编译器">Javac编译器</h2><ol>
<li>解析与填充符号表的过程</li>
<li>插入式注解处理器的注解处理过程</li>
<li>分析与字节码生成过程</li>
</ol>
<h2 id="Java语法糖的味道">Java语法糖的味道</h2><h3 id="Java泛型">Java泛型</h3><p>Java语言中的泛型，在编译后的字节码文件中，就已经被替换为原来的原生类型（Raw Type）了，并且在相应的地方插入了强制转型代码，因此对于运行期Java来说，ArrayList<int>与ArrayList<string>就是同一个类。所以说Java语言中的泛型实现成为类型擦除，基于这种方法实现的泛型被称为伪泛型。<br>将如下代码编译：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">	Map&lt;String, String&gt; map = <span class="keyword">new</span> Map&lt;String, String&gt;();</span><br><span class="line">	map.put(<span class="string">"hello"</span>, <span class="string">"你好"</span>);</span><br><span class="line">	map.put(<span class="string">"how are you?"</span>, <span class="string">"吃了没"</span>);</span><br><span class="line">	system.out.println(map.get(<span class="string">"hello"</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></string></int></p>
<p>将这段代码编译成Class文件，然后在反编译，将会发现泛型都不见了，程序又变成Java泛型出现之前的写法，泛型类型都变回了原生类型，如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(Strings[] args)</span> </span>&#123;</span><br><span class="line">	Map map = <span class="keyword">new</span> map();</span><br><span class="line">	map.put(<span class="string">"hello"</span>, <span class="string">"你好"</span>);</span><br><span class="line">	map.put(<span class="string">"how are you?"</span>, <span class="string">"吃了没"</span>);</span><br><span class="line">	system.out.println(map.get(<span class="string">"hello"</span>));	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>通过泛型擦除法来实现泛型丧失了泛型思想一些应有的优雅</strong></p>
</blockquote>
<p>例如一下代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericTypes</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">(List&lt;String&gt; list)</span> </span>&#123;</span><br><span class="line">	    System.out.println(<span class="string">"Invoke method 1"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">(List&lt;Integer&gt; list)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Invoke method 2"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这段代码不能被正常编译，因为两个参数在编译之后都被擦除了，变成了原生类型List<e>, 擦除动作导致这两个方法的特征签名变得一模一样。</e></p>
<h3 id="自动装箱、拆箱与遍历循环">自动装箱、拆箱与遍历循环</h3><ul>
<li>遍历循环需要被遍历的类实现Iterable接口。</li>
</ul>
<h1 id="晚期（运行时）优化">晚期（运行时）优化</h1><h2 id="概述-1">概述</h2><p>在现在JVM虚拟机中，基本都是解释器和即时编译器共存工作的。</p>
<h2 id="HotSpot虚拟机里面的即时编译器">HotSpot虚拟机里面的即时编译器</h2><p>会被即时编译器编译的“热点代码”有两类：</p>
<ul>
<li>被多次调用的方法</li>
<li>被多次执行的循环体</li>
</ul>
<blockquote>
<p>对于后面一种情况，尽管编译动作时有循环体触发的，但编译器依然会以整个方法作为编译对象。这种编译方法因为编译发生在方法执行过程之中，因此被很形象的称为栈上替换（On Stack Replacement, OSR）。</p>
</blockquote>
<p>在HotSpot虚拟机中使用基于计数器的热点探测方法，它为每个方法准备了两个计数器：方法调用计数器和回边计数器。</p>
<p>下图显示了方法调用计数器触发即时编译：<br><img src="/images/JVM/JVM14.jpg" alt="picture"><br>下图显示了回边计数器触发即时编译：<br><img src="/images/JVM/JVM15.jpg" alt="picture"></p>
<h2 id="Java_vs_C/C++">Java vs C/C++</h2><p>缺点：</p>
<ol>
<li>Java 即时编译器运行占用的是用户程序的时间</li>
<li>Java语言是动态的类型安全语言，所以虚拟机虚拟机需要频繁的进行各种检查，耗费时间。</li>
<li>Java中的多态选择远多余C++语言。</li>
<li>Java的内存回收压力要远大于C/C++语言。<br>优点：</li>
<li>开发的效率会更高</li>
<li>Java的即时编译器能进行动态优化，而C++不行。</li>
</ol>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/2015/08/04/deep-into-JVM-4-1/" itemprop="url">
                  深入理解JVM(5)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2015-08-04T21:43:42+08:00" content="2015-08-04">
              2015-08-04
            </time>
          </span>

          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>这是我写的关于《深入理解Java虚拟机：JVM高级特性与最佳实战（第2版）》的读书笔记。</p>
<h1 id="虚拟机类加载机制">虚拟机类加载机制</h1><p>与C++语言在编译时需要进行链接工作不同，Java语言里，类的加载和链接都是在运行时完成的，Java语言的动态扩展的特性便是依赖运行期动态加载和动态连接这个特点实现的。</p>
<h2 id="类加载的时机">类加载的时机</h2><p>类从加载到虚拟机内存中开始，到卸载出内存为止，共经历了七个阶段。<br><img src="/images/JVM/JVM10.jpg" alt="类的生命周期"><br>如图，加载、验证、准备、初始化和卸载这五个过程是确定的，解析过程则不一定：它在某些情况下可以在初始化之后开始，这样是为了支持Java语言的运行时绑定。<br>jvm规定了下面四种情况需要立即对类进行“初始化”（而加载，验证，准备工作自然要在此之前）：</p>
<ol>
<li>遇到new、getstatic、putstatic、invokestatic这四条指令时，如果类没有进行初始化(被final修饰、已在编译期把结果放入常量池的静态字段除外)，需要先触发初始化。</li>
<li>遇到java.lang.reflect包方法对类进行发射调用时。</li>
<li>当一个类进行初始化时，如果发现其父类还未进行初始化时。</li>
<li>当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化这个主类。</li>
</ol>
<p>以上四类场景成为类的主动引用，除此之外所有引用类的方式，都不会触发初始化，成为被动引用。</p>
<h2 id="类加载的过程">类加载的过程</h2><h3 id="1-加载">1.加载</h3><p>在加载阶段，虚拟机需要完成以下三件事情：</p>
<ol>
<li>通过一个类的全限定名来获取此类的二进制字节流</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</li>
<li>在java堆中生成一个代表这个类的java.lang.Class对象，作为方法区这些数据的访问入口</li>
</ol>
<h3 id="2-验证">2.验证</h3><p>验证阶段虚拟机类加载机制里面的一项很重要的步骤。主要包括四个阶段。</p>
<ol>
<li>文件格式验证</li>
<li>元数据验证</li>
<li>字节码验证</li>
<li>符号引用验证：确保解析动作的职场执行。</li>
</ol>
<h3 id="3-准备">3.准备</h3><p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配。</p>
<blockquote>
<p>这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。</p>
</blockquote>
<h3 id="4-解析">4.解析</h3><p>解析阶段是虚拟机将常量池内符号引用替换为直接引用的过程。<br>解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行。</p>
<ol>
<li>类或接口的解析<br>假设当前代码所处的类为D,如果要把一个从未解析过的符号引用解析为一个类或接口C的直接引用，那虚拟机完成整个解析的过程需要包括以下3个步骤：<ol>
<li>如果C不是一个数组类型，那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C。</li>
<li>如果C是一个数组类型，并且数组类型为对象，那就按照点1的规则进行。<br>3.略</li>
</ol>
</li>
<li>字段解析</li>
<li>类方法解析</li>
<li>接口方法解析</li>
</ol>
<h3 id="5-初始化">5.初始化</h3><p>类初始化阶段是类加载过程的最后一步。在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器<clinit>()方法的过程。</clinit></p>
<ul>
<li><clinit>()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块(static{} 块)中的语句合并产生的。</clinit></li>
<li><clinit>()方法与类的构造函数(或者说实例构造器<init>()方法)不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的<clinit>()方法执行之前，父类的<clinit>()方法已经执行完毕。</clinit></clinit></init></clinit></li>
<li>由于父类的<clinit>()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。</clinit></li>
<li><clinit>()方法不是必须的。</clinit></li>
</ul>
<h2 id="类加载器">类加载器</h2><p>定义：虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块被称为“类加载器”。</p>
<h3 id="类与类加载器">类与类加载器</h3><p>对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性。</p>
<h3 id="双亲委派模型"><strong>双亲委派模型</strong></h3><p>从Java开发人员的角度来看，类加载器可以分为三类。<br><img src="/images/JVM/JVM11.PNG" alt="类加载器"></p>
<ul>
<li>启动类加载器（Bootstrap ClassLoader）:Bootstrap类加载器通常是由本地码实现的，因为它在JVM被装载时就被实例化了。Bootstrap类加载器负责加载基础的Java API,像rt.jar。它只加载在启动路径上的类。</li>
<li>扩展类加载器（Extension ClassLoader）:Extension 类加载器加载标准的Java扩展API，像安全扩展功能。</li>
<li>应用程序类（系统类）加载器（System class ClassLoader）：负责加载用户类路径上所指定的类库。</li>
</ul>
<p>双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这个类加载器之间的父子关系一般不会以继承的关系实现，而是使用组合关系来复用父加载器的代码。</p>
<p>双亲委派模型的工作过程是：如果一个类加载器受到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去实现，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有扎到所需要的类）时，子加载器才会尝试自己去加载。<br>双亲委派模型的好处是：保证了Java程序的稳定运行。</p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


 </div>

        

        
      </div>

      
        
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/default_avatar.jpg" alt="Fu Xi" itemprop="image"/>
          <p class="site-author-name" itemprop="name">Fu Xi</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">16</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">0</span>
              <span class="site-state-item-name">categories</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">11</span>
              <span class="site-state-item-name">tags</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
            <p class="site-author-name">Links</p>
            
              <span class="links-of-author-item">
                <a href="http://tsien.github.io/" target="_blank">Tsien</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.cnblogs.com/netfocus/" target="_blank">netfocus</a>
              </span>
            
          
        </div>

      </section>

      

    </div>
  </aside>


      
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy;  2013 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="icon-next-heart fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fu Xi</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    
    

  


  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.2"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.2"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.2" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.2"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }

      motionIntegrator.bootstrap();
    });
  </script>

  
  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
</body>
</html>
